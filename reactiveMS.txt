Why Reactive Programming ?

Before we jump into reactive programming part lets talk about how the programming in general have evolved and what is a current state of programming
  - Before 10 to 15 yrs ago, the appl that we used to build was monolithic appl which run in appl server and this model does not embrace distributed system
  - Now we are living in the world of microservices which runs in cloud infrastructure where the appl run in the cloud env and also suited for distributed system 
  - The web usage in general is increased compared to 10 to 15 yrs ago and the expectations of the appl that we build also changed

Expectation of the application
   - The appl should scale according to the load. Consider we have online shopping appl if the number of users increased than the expected value then the appl should scale its resources to handle the load 
   - Use resources efficiently - Lets say u make a call to the database or an external service to get some data and during the scenarios we wait until the responses returned from external resources, waiting on something in general is not effective resource utilization
   - Latency (ie) response time of the request should be faster to meet the customer need, so the API should perform as fast as possible 

So in todays REST API development we have 3 ways to develop the REST aplication
  1. client communicate to back end and collect data from database
  2. client communicate to back end and communicate with other service
  3. client communicate to back end and collect data from database and communicate with database

How traditional Restful apis handle concurrent request ?
   The model we take is 
Thread Per Request Model:
    For each HTTP request the tomcat is going to take a thread from the thread pool and assign the thread to that HTTP request. Each allocated thread is responsible to handle the life cycle of thaat HTTP request 
   The threads can be extended only to a value of n which is nothing but the thread pool size because that  is the one which is going to decide how many number of concurrent users can be handled at any given time 

How can we increase or decrease the thread pool size?
    There is the property used to manage the value of thread pool using
     server.tomcat.max-threads
   By default it can handle 200 connections, so in general it can handle only 200 concurrent users and this value can be overridden in application.properties or application.yml file in sping boot appl. Just because we have an option to override the value it does not mean we can set larger value for the property 
   Each thread takes some memory, the common stack size is 1MB so  higher the thread pool size higher the memory consumption just for the thread instance so if u have larger thread pool basically that leaves you with very less memory for the application processing which means the application will perform poor

How to scale ur application?
    Load is handled using horizontal scaling, which means we create more instance of the appl based on the load.
    For example, we have 3 instance of the appl which means the load is 3 times more than the expected value thats y we have 2 instances up and running here.
    If ur appl is running in some kind of kubernetes or some other container orchestration environment then this is possible. In realtime we will have a load balancer sitting in front of our appl which will take care of distributing the HTTP requests to the application. This model works perfect and this model will work in the future too, but if u run more instances in the cloud is going to add some kind of additional cost to the organization
   So we have a limitation when it comes to handling many concurrent users, so the idea of reactive programming is to move away from the thread per request model and handle higher loads of requests with less number of threads 


Traditional REST API design
    - Consider we have an API that relates to the retail  industry, this endpoint gets id as an input from the client and then returns the response entity of type Item.
   Item has 2 additional details like price and location where this item is avialable. To return the item with all the information, first we make a database call and get the price of the item. And then make a rest call to get the location where this item is available. And then we build the item together with price and location infomation and finally response that to the client

@GetMapping("/v1/items/{id}")
public ResponseEntity<Item> getItemFromExternalServices(@PathVariable Integer id) {
    Price price=priceRepo.findById(id).get(); //1. db call
    ResponseEntity<Location> locationEntity=restTemplate.getForEntity(locationUrl,Location.class);  //2. rest call
    Item item=buildItem(price,locationEntity.getBody());
    return ResponseEntity.ok(item);
}

  This coding is called imperative style coding and the API is called imperative style API where the execution goes from top-down approach which means first we made database call followed by that we made the rest call to get the location, we go one by one then we build the item and responded that to client
   Imperative style API by nature they are synchrounos and blocking which means first we make request and then we got a thread assigned to that request by tomcat and we make database call, so after the call is made we are in state called blocking state, the thread dosent do anything until the response is received from the database which means imperative style of programming leads to inefficient use of resources 
   Synchronous aspect of the traditional API is lets assume the latency of this endpoint is 2ms, the db call takes 1ms followed by that REST API call takes 1ms which sums to 2ms for this simple usecase.
   But in reality you might be doing lot of external resource calls before responding to client requests . If u want to improve the response time of this endpoint then we need to make these calls asynchronous which means we make this calls non blocking 
   In Java we have 2 options, Callback and Future.

Callbacks
    - By nature it is complex and not a great option
    - Callbacks does not return any value but it does take the instance of callback as an parameter 
    - Callback code has a nature of handling exceptions at each level and the code itself is hard to read and maintain 

Future
   - Another alternative to write asynchronous code in Java
   - Future returns Future instance and we use Future instance to check whether the data is available, we have methods to call and check whether the data is available or not
   - Hard to compose multiple asynchronous operations with Future 
    
    Considering this limitation we have advanced Future API called CompletableFuture

CompletableFuture
     - Introduced as part of Java8
     - simple to work with and has support for functional style API 
     - Easy to compose multiple asynchronous request but  completableFuture is not great fit for asynchronous methods which involves multiple items in the response and the error handling not that great 

So it is not easy to improve the latency with the traditional REST API design which uses imperative style of programming 
  
We take an another example, 
    @GetMapping("/v1/items")
    public ResponseEntity<List<Item>> getAllItems() {
       List<Item> items=itemRepo.getAllItems();
       return ResponseEntity.ok(items);
    }
this endpoint returns all items in the inventory then the response object size would be large and if this endpoint is have many requests then
   1. Application might crash with out of memory error
   2. client will get such a huge response where the client might not be able to handle 

How do we avoid this happening?
    If there is way for the app to communicate to the source which is DB in the scenario and provide a feedback as DB to slow down since it was sending too much data, this concept is called back pressure 
    So with imperative style api's, the appl does not have a way to communicate to the DB to slow down or reduce the size of the payload so no back pressure compatability in traditional REST API design 

Limitation of Traditional REST API
   1. Limit on the number of concurrent users
   2. They are synchrnous and non blocking
   3. Imperative style API requires a lot of work to do in order to make it asynchronous
   4. No back pressure support 

What is Better API design?
   1. Asynchronous and non blocking 
   2. Move away from thread per request model
   3. Use fewer threads to serve many requests
   4. Back pressure support

What is Reactive programming?
    1. New programming paradigm and complete different way we have been building things in Java
    2. This programming style is asynchronous and non blocking 
    3. Data flow as an event driven stream 
    4. Reactive programming provides Functional style apis just like streams api in Java8
    5. Support back pressure on data streams 

How Reactive programming works?
    We have 2 friends texting each other friend1 and friend2. For the sake of this example, we assume friend1 is watching tv and friend2 is busy outside. Friend1 decide to message friend2, in reality after the message is sent friend1 is not going to wait and block until the response is received from his friend2. After friend2 is complete his job outside, he have chance to reply back to friend1 and conversation proceeds, once they are done with the conversation they are going to do their work. This type of communication is called asynchronous and non blocking, the idea is not to wait and block on anything
   In addition to asynchronous and non blocking aspect, this kind of communication is called message or event driven communication 


How data flow as an event driven stream ?
     Before going to reactive program, we will see how data flow in imperative program.

    List<Item> items=itemRepo.getAllItems();

  The code here uses JPA makes a call to database to retrieve the data. In reality from appl we make call to the db to get the data and then app waits before it gets the data from the database, it goes to block and waiting state until the complete list of items are retrieved. This model is called synchronous and blocking communication model 
   But in reactive model the data will flow as an event or message, so we receive one event for every result item from the data source, the data source can be database or external service or external file etc
   Once all the data is evented out to the caller then we are going to receive a completion event, if there is an error in retrieving the data from external source then we are going to receive an error event 

List<Item> items=itemRepo.getAllItems();
   Here we are going to retrieve list of items from the database. 
   First step is we are making the call to retrieve the list  of items, the call returns immediately because it is asynchronous and non blocking. The data will be pushed to the appl as a stream and as it is available one by one, meaning one event for every single item in the resultset. We recieve onNext() call from db layer to appl layer for every single item and it will continued until all the items are pushed to the appl and this data flow is called event driven stream
    Basically we are not blocked and data is pushed to the appl, now once all the data is pushed we receive an event called onComplete() which means all items are pushed and here is an onComplete event which tells that we dont have any more data 

Error Flow
   We make call to database as like previous example and the call returns immediately,after the first onNext() call which return first item because of some reason we got an exception, in that case instead of abruptly exiting the execution flow which is how imperative style works. 
    But here it is going to send an error event to let the appl know something unexpected happened, so after this event has received we can take care of handling how u want to recover from that exception
    
No data:
   In case of no data flow (ie) for a given search of query there is no result then in that case we just get onComplete() event  from database layer

Save data:
   We discuss save data where return type is void, 
       itemReactiveRepo.save(item);
  The code makes a call to the database to save the item, in those case if save is successful we get onComplete() event or if save is unsuccessful for some reason then we get onError() event 

Data flow as event driven stream
  1. onNext(item) - data stream events
  2. onComplete() -  completion/success events
  3. onError() - error events

Functional Style code
    - similar to streams API
    - easy to work with lambdas 

Back Pressure in data streams
    Reactive programming supports back pressure, if the data source producing more data than we expected then there is a way for the appl to provide a feedback to the data source stating u need to slow down until a catch up , this option is handy when it comes to build stable system in reactive programming
    
    
Reactive Streams Specification https://github.com/reactive-streams/reactive-streams-jvm

    Previously we talk about a data flowing as an event driven stream which means requesting for data and the data flowing to the appl as a event driven stream which is otherwise called Reactive Stream
    - Reactive stream specification is nothing but the specification or rules for a reactive stream to follow. In OOPS we have features like inheritance, encapsulation, polymorphism etc whatever code that we write in OOPS should relate to these concepts 
   - Likewise this specification has rules on how the reactive programming code that we write should follow.
   - who created the specification?
         Engineers from major companies like Pivotal, Netflix, Lightbend and Twitter etc got together and created the reactive stream specification
   - The specification has 4 interfaces
         Publisher, Subscriber, Subscription, Processor
All of these interfaces talk to each other in order for whole reactive stream to flow

1. Publisher
  - It is simple interface with single method called subscribe() which accepts subscriber instance, by making this call the subcriber registers to the publisher
    public interface Publisher<T> {
         public void subscribe(Subscriber<? super T> s);
    } 
Publishers are data producers basically the data source. The example of publishers are database, external service  etc

2. Subscriber interface
    - It has 4 methods
   public interface Subscriber<T> {
       public void onSubscribe(Subscription s);
       public void onNext(T t);
       public void onError(Throwable t);
       public void onComplete();
  }
onNext() is data stream, onComplete() is signal for no more data, onError() is signal that error happened, onSubscribe() which has subscription object as argument 

3. Subcription interface 
      It has 2 methods
    public interface Subscription {
        public void request(long n);
        public void cancel();
    }


Publisher/Subscriber Event flow
     We have publisher at top and subscriber at bottom, publisher is data producer or data emitter, subscriber is one which is going to read the data from the publisher. 
    1. The subscriber is going to invoke subscribe() of publisher and passes the instance of the subscriber as an input. 
    2. After that publisher is going to send a subscription object to Subscriber confirming the subscription is successful 
    3. By default the request method is going to request for all the data and whatever data that you have give it 
    4. Lets publisher is a database and is going to return 100 items in that case there will be 100 onNext() event with each event representing a row will be sent to the subscriber
    5. Once all the data is sent, then we will receive onComplete() event that will be sent to the subscriber 
    There is an option for the subscriber to provide a number to the publisher asking for a specific number of data with request(n). For example out of 100 matching items u just need 2 of the items from the publisher, in that case we pass request(2) then it is going to give 2 onNext() event followed by that we get onComplete() event
   Basically this concept is called back pressure where subscriber has a control on how much data is need from the publisher. If there is any error in whole workflow then it will be receiving an onError() event
   The subscriber has the option to call the cancel() in the subscription that is received from the publisher, which means we are cancelling the subscription and the publisher is not going to publish any event to the subscriber

4. Processor interface
      - It is combination of Publisher and Subscriber interface 
  public interface Processor<T,R> extends Subscriber<T>, Publisher<R> {

}


Reactive Libraries
     - It is implementation of Reactive streams specification like Publisher, Subscriber, Subscription, Processor
     - We have different Reactive Libraries like
   1. RxJava   2. Reactor  
   3. JDK 9 itself has Flow Class with reactive streams

Reactor or Project Reactor
    - Build and maintained by Pivotal
    - Default library that comes with spring boot for writing reactive programming code 

Reactor is a fourth-generation reactive library, based on the Reactive Streams specification, for building non-blocking applications on the JVM

REACTIVE CORE
Reactor is fully non-blocking and provides efficient demand management.  It directly interacts with Java's functional API, CompletableFuture, Stream, and Duration.

TYPED [0|1|N] SEQUENCES
Reactor offers two reactive and composable APIs, Flux [N] and Mono [0|1], which extensively implement Reactive Extensions.

NON-BLOCKING IO
Well-suited for a microservices architecture, Reactor offers backpressure-ready network engines for HTTP (including Websockets), TCP, and UDP.


Project Reactor 
  - It have different modules, but we discuss about
1. reactor core
2. reactor test
3. reactor netty 
4. reactor extra
5. reactor adapter
6. reactor kafka
7. reactor rabbitmq


reactor core 
   - core library of Project reactor
   - It has implementation of Reactive streams specification
   - To work with reactor core we need minimum Java 8 
   - Flux and Mono are two classes which are the implementation of the reactive streams specification. These are the reactive types of project reactor
   - Flux is a class which represents 0 to n elements
   - Mono is a class which represents 0 to 1 elements


Flux - 0 to N element
   - We have marbles at the top and then operator in the middle and then marble at the bottom.
   - Marbles at the top represents the actual data and the operator in the middle represents filtering, transformation and lot of other operations to transform the data from its raw form to another form, it goes to operator layer one by one and below marbles represents the final output which will be sent to the subscriber, the vertical line represents the onComplete, meaning there is no data, X represents there is some kind of error happened in one of the above events 
    So we have marbles at the top which is going to flow one by one which is going to be passed to the operator layer one by one and then the final output will be sent to subscriber

eg:
   Flux.just("Spring","Spring Boot","Reactive Spring boot")
   .map(s->s.concat("flux"))
   .subscribe(System.out::println);

We have flux of 3 elements, in reality we will be pulling the elements from db, here for simple we created flux using just(). Flux have 3 elements and all these elements will be sent one by one, so map() is method which is part of reactive API which is going to convert Spring to Spring Flux, Spring Boot to Spring Boot Flux, Reactive Spring Boot to Reactive Spring Boot Flux and then subscribe is attached to it 
   To summarize we are going to get Spring, Spring Boot, Reactive Spring Boot as each and every element passing down to the next layer which is map layer, in the map layer we are just concatenate in the flux to each and every element and then it goes to subscribe() and print the value 

https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Flux.html
   Documentation of Flux which shows different method, in the above example we saw
1. map()
2. Flux buffer(int size)  -- buffer(3)
       
Mono - 0 to 1 elements
    It is representation of 0 to 1 elements, here we have 1 marble at the top, one marble at bottom, so after 1 element we will receive onComplete() and X represents some kind of error happened in the mono
    Mono is a use case where we request for only one data from database or only one data from rest endpoint 

   Mono.just("Spring").map(s-> s.concat("flux"))
                .subscribe(System.out::println);

Here we use just() method to create mono with one element and we cant provide multiple elts in mono which leads to compilation error, followed by that we are performing map() which transform Spring to Springflux and we have subscribe() to print the value 


Reactive API in Spring Boot
1. Create ReactiveSpringBoot project with reactive web, reactive mongodb, lombok and embedded mongodb(for writing integration test case). Apart from that ur pom.xml will have project reactor which is default reactive library that comes with spring for flux.
   - The default server is Netty 
   - No reactive mysql connector is available
   - If u expand the dependency of project reactor, u can see 3 dependency called project reactor core which has all the flux and mono reactive types, other is reactor test used for testing flux and mono because u cant write it as unit test cases, next is reactor netty which is default server for reactive 

2. Next enable lombok dependency for ur project 

3. We write test cases for flux and mono and then we study about those concepts
  - Create FluxAndMonoTest.java
  - Create fluxTest(), first we will create flux using just() and only way to access elements from flux using subscribing to it, without subscribing there is no point  in flux. When u subscribe thats when the flux is going to start emitting the values to the subscriber 

@Test
public void fluxTest() {
   Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot");
   stringFlux.subscribe(System.out::println);
}

-Run as Flux test
-Now it will print the values one by one so as soon as you subscribe, what this flux does is its going to pass the elements to the subscribe() one by one so it prints the value one by one 

4. Consider some error happens, in that case subscribe() has overloaded method of handling that.
   stringFlux.subscribe(System.out::println,
         (e)->System.out.println(e));
  In order to attach an error to flux we have concatWith() with we are attaching an exception
    Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot")
     .concatWith(Flux.error(new RuntimeException("Exception occured")));

Here the data is going to flow to the subscriber as events, as soon as we call subscribe(), a subscribe event is send to the flux and from there it send the events using onNext() and when there is exception its going to send u onError() with exception and send to subscribe() second argument
   In order to see those events, flux have log() which is used to log all the events that happens behind the scenes when u call subscribe()

Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot")
      .concatWith(Flux.error(new RuntimeException("Exception occured")))
	.log();
  stringFlux.subscribe(System.out::println,(e)->System.out.println(e));

When we run the code,the first step is onSubscribe(), after that we have onRequest() which means the request call with unbounded, basically subscribe request for whatever data u have till maxvalue. As soon as flux receives the request unbounded call, its going to send element one by one that why we se onNext() and then pass the element and print it and it pass next elemt like that, since we have error that why it ended with onError() event. If there is no error then we receive onComplete event 
   
5. Now comment concatWith() and run it, now we can see the process end with onComplete event

6. Now we check after the error whether flux will emit an event or not, for that we create concatWith() after an exception
Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot")
			     .concatWith(Flux.error(new RuntimeException("Exception occured")))
			     .concatWith(Flux.just("After error"))
			     .log();

In this case it wont print "After error" after an exception occured because once the error is emitted from flux then it is not going to send any more data 

7. subscribe() takes 3rd parameter also which gets notified whenever there is onComplete event 

stringFlux.subscribe(System.out::println,(e)->System.out.println(e),()->System.out.println("Completed"));


Writing Junit test for Flux
1. Now we are going to test flux without any error, so we are not going to have error part 

Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot").log()

We are going to test the elements inside the flux which is spring, spring boot, reactive spring boot and the order in which elements are flowing to the subscriber 
   In order to test the elements, reactor test is a module that we are going to use it and it has class called StepVerifier class. We write StepVerifier class which contains create() method which takes flux as argument
          StepVerifier.create(stringFlux);
  Next we have to define what is expected, for that we use expectNext() with 3 values and finally we have verifyComplete() for completion of flux
   StepVerifier.create(stringFlux)
          .expectNext("Spring")
          .expectNext("Spring Boot")
          .expectNext("Reactive Spring Boot")
          .verifyComplete();
If we change the order, then the test case it would be failed. So this test case make sure that we are getting the elements from the flux in the order that we have it here 
  The difference between 2 methods is that subscribe() is one which is going to start the whole flow of the flux to pass the elements from flux to the subscriber,  but here StepVerifier take care of subscribing to the flux and then asserting the values on the flux
   When we comment verifyComplete() and run then we wont get any output because verifyComplete is a call which is actually equivalent to subscribe which iss going to start the flow of elements from the flux.

   Instead of defining expectNext() multiple times, we can define in a single line also 
  .expectNext("Spring","SpringBoot","Reactive spring boot")


2. Next we create fluxTest_WithError() to check for errors. 
   Here error is going to be last event, because we provide concatWith() which generates the error. In order to test the error case we have expectError() followed by verify(). verify() is one which start the whole flow of flux to subscriber 

@Test
	public void fluxTest_WithError() {
		Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot")
				.concatWith(Flux.error(new RuntimeException("Exception occured")));
		 StepVerifier.create(stringFlux)
         .expectNext("Spring")
         .expectNext("SpringBoot")
         .expectNext("Reactive spring boot")
         .expectError(RuntimeException.class)
         .verify();
	} 

If you want to verify only the message inside exception, for that we have expectErrorMessage(), we cant have both expectError() and expectErrorMessage()

3. We dont want to validate all values, we want to validate the number of elements that particular flux is gonna emit, in that we use expectNextCount()

@Test
	public void fluxTestCount_WithError() {
		Flux<String> stringFlux=Flux.just("Spring","SpringBoot","Reactive spring boot")
				.concatWith(Flux.error(new RuntimeException("Exception occured")));
		 StepVerifier.create(stringFlux)
         .expectNextCount(3)
         .expectErrorMessage("Exception occured")
         .verify();
	}

Writing Junit test for Mono
1. Create monoTest(), we are creating Mono with just() which takes only one element 

@Test
	public void monoTest() {
		Mono<String> stringMono=Mono.just("Spring");
		StepVerifier.create(stringMono)
		.expectNext("Spring")
        .verifyComplete();
	}
When we run verifyComplete(), first call is onSubscribe() then we request for unbound data but in mono it is always 1 data so we got next event which is onNext from Mono and then onComplete event is called 

2. Next we check errors in Mono, we create monoTest_Error()